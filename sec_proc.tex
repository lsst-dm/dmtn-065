\section{Processing Data from Special Programs}\label{sec:proc}

A discussion of the anticipated details and challenges related to 
obtaining and processing data from Special Programs.

Appendix~\ref{sec:spcs} provides detailed examples for the processing
of data from Special Programs, including scenarios in which regular,
Special, and User-Generated Processing are all involved.

\subsection{Boundaries on Non-Standard Visits} \label{ssec:proc_bounds}

Special Programs that do not use standard or alternative standard visits
might be affected by hardware or processing boundaries.

\subsubsection{Hardware Boundaries}\label{ssec:proc_bounds_hardware}

Appendix~\ref{sec:hardbounds} lists all of the hardware boundaries that 
might constrain the potential diversity of Special Programs data.

In general, the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.

A few potential challenges posed by hardware
boundaries are summarized below.

\begin{itemize}

\item \textbf{Short exposures --}
Special Programs that use short exposures would be limited to the
minimum exposure time is 1 second (stretch goal: 0.1 seconds).
There is a potential hardware boundary that limits the readout rate to 1 
every 15 seconds, which would affect the image acquisition rate and 
increase the overheads on short exposures.

\item \textbf{Repeated pointing --}
Special Programs which require the \emph{exact same} field pointing and 
rotation for \emph{every exposure} (to sub-arcsecond levels) might run 
into hardware boundaries on pointing and tracking.

\item \textbf{Twilight images --}
Special Programs that obtain twilight images will be subject to safe
limits on sky background flux, as with any astronomical camera.

\end{itemize}

Finally, as a side note, Special Programs that request a high number of 
filter changes and/or long slews could be inefficient due to large overheads,
but would not be limited by hardware boundaries.

\subsubsection{Processing Boundaries}\label{ssec:proc_bounds_processing}

Appendix~\ref{sec:procbounds} describes the boundaries on what types of visits 
can be processed and calibrated by the Data Management System and the LSST
Science Pipelines.

Most of the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.
However, those which use non-standard visits, especially those with
short exposure time or those obtained during twilight, might
be affected by processing boundaries.

The most likely challenges posed by processing
boundaries are summarized below.

\begin{itemize}

\item \textbf{Very short exposures --}
Special Programs which use very short ($<$2 sec) exposures 
could be difficult to reduce due to an incompletely-formed PSF 
(Section~\ref{ssec:procbounds_expt}).
The Data Management System is required to be able to process exposure 
times as low as 1 second (Section~\ref{ssec:req_proc}), 
but it is known that such short exposures might have degraded image quality.

\item \textbf{Very short or very long exposures --}
Special Programs that use very short or very long ($>$150 sec) 
exposures could be difficult to calibrate due to having too few 
(or too few unsaturated) stars.

\item \textbf{Twilight images --}
For Special Programs which obtain images with very bright sky backgrounds
(twilight images), it is currently unclear whether they can be processed
with the LSST Science Pipelines; 
User-Generated Processing might be needed (e.g., \citealt{2022AJ....164..168S}).

\item \textbf{Streaked images --}
The full reduction and calibration of data from any Special Programs that 
use non-sidereal tracking, which produce images with star streaks, is
currently beyond the scope of the LSST Science Pipelines; 
User-Generated Processing would be needed.

\end{itemize}

\subsection{Regular (non-special) processing}\label{ssec:proc_reg}

Recall that the term ``regular processing" is used only within this document,
and refers to the image processing pipelines that are designed for, 
and will be applied to, the WFD program's observations (Section~\ref{sec:intro}).

Decisions about when to apply regular processing to Special Programs data,
or when to include it in the data products for the WFD program 
(e.g., if it improves the all-sky coadds), 
are ultimately left to the discretion of the Rubin Observatory's 
Data Management and System Performance teams.


\subsubsection{Prompt Processing and Alert Production}\label{sssec:proc_reg_prompt}

As described in Section~\ref{ssec:sci_pproc}, 
all visits that \emph{can} be processed by the Prompt pipelines and generate 
alerts \emph{should} be, in support of time domain and Solar System science goals.

\textbf{The meaning of ``can be processed".}
This is ultimately left to the discretion of
Rubin Data Management in Rubin Operations, but is expected to include
all standard and alternative visits in sky regions for which a template image exists.
This might also include some non-standard visits (shorter or longer exposures), 
as long as they can be processed by the Prompt pipeline and an appropriate template image exists.
Visits with very short or very long exposure times (or very bright sky 
backgrounds) might be excluded if they would need specialized algorithms for,
e.g., instrument signature removal, difference-imaging, template-generation 
(Section~\ref{ssec:proc_bounds}).
Alert latency requirements do apply to Special Programs data (Section~\ref{ssec:req_proc}),
and if they cannot be met then Prompt processing is ``not possible".

\textbf{The use of specialized (alternative) template images.}
If a Special Program's primary science goal requires specialized templates and 
Prompt processing, the Data Management System will have the capability to load 
and use an alternative template for some sky regions, based on the image metadata 
(i.e., the labels described in Section~\ref{ssec:sci_labels}). 
However, there would not be enough memory to hold alternative templates 
for the whole sky.

\textbf{How WFD and Special Program data would co-exist.}
No ``unique and separate" data products for the Special Progams would be 
produced by regular Prompt processing.
Special Programs data that is processed by the Prompt pipeline would 
contribute to the Prompt data products for the WFD program as 
described in Section 3 of the DPDD \citedsp{lse-163}. 
These data products are the results of Difference Image Analysis (DIA),
such as the difference images, catalogs of sources detected in difference
images ({\tt DiaSources}) and associated static-sky {\tt DiaSources}
into {\tt DiaObjects}, and alert packets.

Including visits from Special Programs in regular Prompt processing alongside
vists from the WFD program is not, in general, anticipated to affect WFD science goals.
For example, analyses for a WFD-only subset could still be done using the program and
region labels described in Section~\ref{ssec:sci_labels}, which would be
propogated to difference images, difference-image catalogss, and alerts.

\textbf{Potential issues with Prompt processing for untiled sequences from Special Programs.}
There are two potential issues with Prompt processing for DDFs, or any mini-survey 
that obtains a sequence of untiled images: images at the same pointing or which overlap.
For example, a DDF which obtains a hour-long series of about a hundred images at the same coordinates,
every few nights for a few months.

\begin{enumerate}

\item \textbf{DIA Object histories may become too large for the sizing model.}
Alert packets contain the full records of all associated 
{\tt DiaSources} from the past 12 months, but the alert
stream bandwidth is sized for the expected histories for
WFD program fields. 
The Prompt pipeline resources are also sized for the
WFD program, and it might not be possible to load up
thousands of epochs at a time.
The Data Management team will have to test the realized
capabilities of Prompt processing and alert distribtuion,
and potentially impose a mitigation strategy such as
limiting histories to the last $N$ observations instead
of the last 12 months in heavily-observed regions.

\item \textbf{The association of new DIA Sources into DIA Objects may be compromised.}
For consecutive images, processing for the second image begins when the processing for the 
first image is only halfway done.
At this point, the {\tt DiaObject} catalog has 
not yet been updated with the new {\tt DiaSources} detected in the first image.
Thus, the {\tt DiaSource}s from images one and two for a new transient 
would not be associated with a single {\tt DiaObject}, but instead would 
each instantiate a new {\tt DiaObject}.

\end{enumerate}

These two potential issues pose challenges, but are not necessarily showstoppers in processing 
Special Programs data with the Prompt pipelines. 
The overall impact on time-domain science would still be positive, even 
if mitigations are needed for these issues.
For example, brokers and users would be able to use the region and program labels
in the data as context (i.e., as flags) and avoid including 
limited-history or potentially-compromised {\tt DiaSources} in their
analyses if necessary.

\subsubsection{Solar System Processing}\label{sssec:proc_reg_ss}

Since Solar System Processing takes {\tt DiaSource}s as input, any 
Special Programs images that are processed by the Prompt pipeline
could be incorporated into Solar System Processing.

\subsubsection{Data Release Processing}\label{sssec:proc_reg_dr}

\textbf{Time-domain DIA data products --}
This includes the results of the annual reprocessing of WFD program data with 
Difference Image Analysis (DIA), and the production of Data Release
versions of the processed images (single-visit and difference images)
and associated catalogs ({\tt DiaSource}, {\tt DiaObject}, {\tt Source},
{\tt ForcedSource}, {\tt DiaForcedSource}, and so on).
These data products will be used primarily for time-domain science.
They should include Special Programs data for the same reasons as
provided in Section~\ref{ssec:sci_pproc}, and with the same 
considerations as discussed in Section~\ref{sssec:proc_reg_prompt}.
This processing should use the same template image for a given field.

\textbf{Static-sky data products --}
This includes the tessellation and coaddition of WFD program images
and the associated multi-band {\tt Object} catalog and survey property maps.
Whether and how to include any Special Programs data in these data products
is left entirely to the discretion of the Rubin Data Management team in Operations.
As an example, perhaps Special Programs images will only be included when they 
assist with uniformity or suppress edge effects or low-order modes in the 
all-sky photometric solutions.

\subsection{Special Processing}\label{ssec:proc_special}

As described in Section~\ref{ssec:sci_sproc}, 
Special Processing should be done by Rubin Data Management to 
produce unique and separate data products
for Special Programs when it is both possible and necessary.
This is a requirement (Section~\ref{ssec:req_dp}).

In short, \emph{possible} means that original or reconfigured versions of the LSST
Science Pipelines can be used , and \emph{necessary} means the primary science goal for Special Program
could not be met without the data products produced by the Special Processing.

\textbf{Joinable tables --}
Any tables for the unique and separate data products should be joinable to the 
data products for the WFD program, when possible.
This is a requirement (Section~\ref{ssec:req_dp}).

\textbf{Survey property maps --}
As for the tesslated all-sky coadded images made from WFD program data, survey property maps
should be made individually as part of any Special Programs that generates
tesselated coadded images. This is \emph{not} a requirement (Section~\ref{ssec:req_dp}).


\textbf{Special Processing timescales --}
The timescales for Special Processing should be adopted that best serve the
primary science goal for the Special Program.
For example, nighly-coadd difference-image analysis for DDFs is the most
scientifically useful if done on a daily cadence, but the deeply coadded
images for DDF fields could be released annually.

The interpretations of possible and necessary, and the scope of Special Processing,
are ultimately left to the discretion of Rubin Data Management in Operations.

Specific examples are provided only to illustrate this interpretation of possible and necessary.
These examples do not place limits on what Special Processing might be done.

\begin{itemize}

\item \textbf{Possible and necessary:}
in order to detect high-redshift (faint) galaxies in the DDFs,
Rubin Data Management uses the LSST Science Pipelines to deeply
coadd images for each field, and store the results of source
detection and characterization in unique and separate tables that
are included in the annual data release.

\item \textbf{Possible but not necessary:}
a time-domain mini-survey that uses standard visits \emph{could}
have separate difference-image analysis object and source catalogs
generated, but this is not necessary as the science goals for the
mini-survey can be met by processing its data with regular Prompt
Processing, and ensuring the data is properly labeled.

\item \textbf{Possible but not necessary (secondary science goals):}
a time-domain mini-survey (or DDF) has a secondary science goal of detecting
precursor outbursts for transients, which requires coadding images
within windows of days, weeks, and months to reach various depths.
This set of custom coadds may be considered as ``not necessary" and requiring 
User-Generated Processing.
Note that for the WFD program data, such custom coadds are also considered 
as beyond scope and in need of User-Generated Processing.

\item \textbf{Necessary but not possible:}
in order to find the most distant, faint Kuiper Belt Objects in the DDF,
a specialized, computationally intensive form of ``shift-and-stack" processing
is required for detection, but such algorithms are not used by the 
LSST Science Pipelines and so User-Generated Processing will be needed.
A second example is a twilight survey that uses non-standard visits 
which are outside the boundaries of what the LSST Science Pipelines can process.

\end{itemize}

Further examples of potential Special Processing for anticipated Special Programs are provided below.

\subsubsection{Deep Drilling Fields (DDFs)}\label{sssec:proc_special_ddf}

As the DDFs will likely be observed with standard or alternative standard 
visits, Data Management will be able to reconfigure existing pipelines for
Special Processing to produce unique and separate DDF data products.

For example, Special Processing for the DDF data products might include:
\begin{itemize}
\item nightly-coadded images (24 h)
\item nightly-coadded difference images (24 h)
\item {\tt DiaSource}- and {\tt DiaObject}-like catalogs for the nightly-coadds (24 h)
\item deeply-coadded images (all images to date; yearly)
\item templates for the nightly-coadded difference images (yearly)
\item {\tt Source}- and {\tt Object}-like catalogs for the nightly-coadded and deeply-coadded images (yearly)
\end{itemize}

\subsubsection{Short-Exposure Mini-Surveys}

As described in \citedsp{PSTN-055}, there are a few
short-exposure mini-surveys are under consideration.
Two examples are a short exposure map of the sky in $ugrizy$ for calibration,
and a Near-Earth Objects (NEO) twilight survey.

Special Processing for short-exposure mini-surveys remains to
be determined.
Since it falls under the remit of Data Management to perform proper calibration,
an evaluatation of whether short exposures for calibration are necessary
will be done. 
If Data Management does find that short-exposure and/or high-sky brightness images
can be processed with reconfigured versions of the LSST Science Pipelines,
then unique and separate data products could be generated with Special Processing.
For the NEO twilight survey, these data products would likely be similar to the
Prompt or DIA data products.
For the calibration survey, these data products would like be similar to the
annual data release tessellated coadds and associated catalog.

\subsubsection{Standard Visit Mini-Surveys}

Consider a Special Program in which a special region of sky is observed with standard
visits but a a special strategy or cadence which is significantly distinct from the WFD program,
and lasts for a limited amount of time.
For example, a short-term survey of the Magellanic Clouds, with dual primary science
goals in time-domain and static-sky science.

In cases like this, a set of unique and separate data products with the same formats as the 
time-domain DIA and static-sky data products described in Section~\ref{sssec:proc_reg_dr}
should be created with Special Processing.
They might be released with an annual data release or on an intermediate timescale, e.g.,
within six months of the conclusion of the mini-survey observations.

\subsubsection{Target-of-Opportunity (TOO) Observations}

Options for RDM to process TOO observations, especially during the first year of Operations 
when the template coverage will be low, are discussed in more detail in 
\citeds{rtn-008}.

\subsection{User-Generated Processing}\label{ssec:proc_user}

Science goals that require data products which are not possible to create with 
the original or reconfigured versions of the LSST Science Pipelines, 
and/or for which new algorithmic development or significant computational resources 
are needed, will require user processing and user-generated data products.
As described above, custom coadds (e.g., weekly, monthly) are also left to users 
to generate, as required by their specific science goals.

\textbf{Computational resources -- }
Users will have access to the LSST Science Pipelines and data processing 
infrastructure, as well as dedicated computational resources next-to-the-data, 
via the Rubin Science Platform; \citeds{lse-319}.
Details of the planned ``User Batch" facility for data processing are described in 
\citeds{dmtn-202}.
Very computationally intense user processing might require external resources. 

\textbf{Adopting user code or data products --}
It is expected that some User-Generated pipelines and data products 
might be ``adopted" or ``federated" into the LSST Science Pipelines and the Prompt 
and Data Release data products.
Details regarding this are to be provided elsewhere.

\textbf{Alert production is restricted -- }
User-Generated Processing will not be able to release alert packets in the LSST alert stream.
As the latency on processed visit image availability has an 80-hour
embargo, no user-generated pipeline will be able to process Special Programs 
data on a timescale similar to prompt processing and alert production 
(60 seconds to 24 hours).
Thus, no User-Generated Processing may contribute alerts to the LSST alert stream on 
any timescale.

Further examples of potential User-Generated Processing for anticipated Special Programs are provided below.

\subsubsection{Deep Drilling Fields}

User-Generated Processing and data products might include, for example, DDF images coadded 
on custom timescales (e.g., weekly, monthly), or coadded using algorithms outside of the 
LSST Science Pipelines.

\subsubsection{Short-Exposure Mini-Surveys}

Short-exposure images obtained during twilight, which will have a very bright sky 
background unlike other LSST images, might require specialized algorithms
to subtract the high sky background which are not available in the LSST Science Pipelines,
and might require User-Generated Processing.

Short-exposure images obtained during the night might have too-few stars to satisfy the
astrometric and photometric calibration routines in the LSST Science Pipelines,
and might require User-Generated Processing.

\subsubsection{Mini-Surveys}

Mini-surveys with time-domain science goals that aren't met by the Prompt pipelines, 
e.g., those that require difference imaging with coadded images on an intermediate 
timescale (e.g., a weekly stack), would require User-Generated Processing.
