\section{Processing Data from Special Programs}\label{sec:proc}

A discussion of the anticipated details and challenges related to 
obtaining and processing data from Special Programs.

Appendix~\ref{sec:spcs} provides detailed examples for the processing
of data from Special Programs, including scenarios in which regular,
Special, and User-Generate Processing are all involved.

\subsection{Boundaries on Non-Standard Visits} \label{ssec:proc_bounds}

Special Programs that do not use standard or alternative standard visits
might be affected by hardware or processing boundaries.

\subsubsection{Hardware Boundaries}\label{ssec:proc_bounds_hardware}

Appendix~\ref{sec:hardbounds} lists all of the hardware boundaries that 
might constrain the potential diversity of Special Programs data.

In general, the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.

A few potential challenges posed by hardware
boundaries are summarized below.

\begin{itemize}

\item Special Programs that use short exposures would be limited to the
minimum exposure time is 1 second (stretch goal: 0.1 seconds).
There is a potential hardware boundary that limits the readout rate to 1 
every 15 seconds, which would affect the image acquisition rate and 
increase the overheads on short exposures.

\item Special Programs which require the \emph{exact same} field pointing and 
rotation for \emph{every exposure} (to sub-arcsecond levels) might run 
into hardware boundaries on pointing and tracking.

\item Special Programs that request a high number of filter changes and/or long 
slews could be inefficient due to large overheads, but there are no
boundaries on how data can be obtained.

\item Special Programs that obtain twilight images will be subject to safe
limits on sky background flux, as with any astronomical camera.

\end{itemize}

\subsubsection{Processing Boundaries}\label{ssec:proc_bounds_processing}

Appendix~\ref{sec:procbounds} describes the boundaries on what types of visits 
can be processed and calibrated by the Data Management System and the LSST
Science Pipelines.

Most of the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.
However, those which use non-standard visits, especially those with
short exposure time or those obtained during twilight, might
be affected by processing boundaries.

The most likely challenges posed by processing
boundaries are summarized below.

\begin{itemize}

\item Special Programs which use very short ($<$2 sec) exposures 
could be difficult to reduce due to an incompletely-formed PSF 
(Section~\ref{ssec:procbounds_expt}).
The Data Management System is required to be able to process exposure 
times as low as 1 second, but it is known that such short exposures might 
have degraded image quality.

\item Special Programs that use very short or very long ($>$150 sec) 
exposures could be difficult to calibrate due to having too few 
(or too few unsaturated) stars.

\item For Special Programs which obtain images with very bright sky backgrounds
(twilight images), it is currently unclear whether they can be processed
with the LSST Science Pipelines; User-Generated Processing might be needed.

\item The full reduction and calibration of data from any Special Programs that 
use non-sidereal tracking, which produce images with star streaks, is
currently beyond the scope of the LSST Science Pipelines; 
User-Generated Processing would be needed.

\end{itemize}

\subsection{Regular (non-special) processing}\label{ssec:proc_reg}

Recall that the term ``regular processing" is used only within this document,
and refers to the image processing pipelines that are designed for, 
and will be applied to, the WFD program's observations (Section~\ref{sec:intro}).

Decisions about when to apply regular processing to Special Programs data,
or when to include it in the data products for the WFD program 
(e.g., if it improves the all-sky coadds), 
are ultimately left to the discretion of the Rubin Observatory's 
Data Management and System Performance teams.


\subsubsection{Prompt Processing and Alert Production}\label{sssec:proc_reg_prompt}

This might also include some non-standard visits (shorter or longer exposures), 
as long as they can be processed by the Prompt pipeline and an appropriate template image exists.
Visits with very short or very long exposure times (or very bright sky 
backgrounds) might be excluded if they would need specialized algorithms for,
e.g., instrument signature removal, difference-imaging, template-generation 
(Section~\ref{ssec:proc_bounds}).

If a Special Program's primary science goal requires specialized templates and 
Prompt processing, the Data Management System will have the capability to load 
and use an alternative template for some sky regions, based on the image metadata 
(i.e., the labels described in Section~\ref{ssec:sci_labels}). 
However, there would not be enough memory to hold alternative templates 
for the whole sky.

Including visits from Special Programs in regular Prompt processing alongside
vists from the WFD program is not, in general, anticipated to affect WFD science goals.
For example, analyses for a WFD-only subset could still be done using the program and
region labels described in Section~\ref{ssec:sci_labels}.


OLD


As all visits can contribute to the time-domain astronomy science goals 
of the LSST, all Special Programs data that {\it can} be processed by the 
prompt processing and alert production pipelines {\it should} be, 
alongside visits from the WFD.

This would include all standard and alternative visits in sky regions for which 
a template image exists.
This might also include some non-standard visits (shorter or longer exposures) 
as long as they can be processed by the Prompt 
pipeline\footnote{If a Special Program's science goals do require 
specialized templates and 
Prompt processing, the DMS will have the capability to load and use an 
alternative template for some regions, based on the image metadata. 
However, there would not be enough memory to hold alternative templates 
for the whole sky region.}.

Visits with very short or very long exposure times (or very bright sky 
backgrounds) might be excluded if they would 
need specialized algorithms for difference-imaging or template-generation.

Special Programs data that is processed by the Prompt pipeline would 
contribute to the Prompt data products described in Section 3 of the 
DPDD \citedsp{lse-163}. 

Difference images, {\tt DiaSources}, and alerts would have region and 
program labels (Section~\ref{ssec:sci_labels}), providing origin and
provenance for brokers and users.

\textbf{Two potential issues with Prompt processing for DDFs}, 
or any mini-survey that obtains a sequence of images without slewing, 
include:

(1) As alert packets contain the full records of all associated 
{\tt DiaSources} from the past 12 months, alerts for {\tt DiaObjects} in 
the DDFs might become very large.

(2) The association of {\it new} {\tt DiaSources} into {\tt DiaObjects} 
will be somewhat compromised for a DDF sequence.
The processing for the second image begins when the processing for the 
first image is only halfway done; when the {\tt DiaObject} catalog has 
not yet updated with the new {\tt DiaSources} detected in the first image.
Thus, the {\tt DiaSource} from images one and two for a new transient 
would not be associated with a single {\tt DiaObject}, but instead would 
each instantiate a new {\tt DiaObject}.

These two issues would not impact time-domain science.
Brokers and users would be able to use the region and program labels
in the data as context (i.e., as flags for potentially-compromised 
data products) and, for example, avoid DDF alerts should they so choose.


\subsubsection{Solar System Processing}\label{sssec:proc_reg_ss}

Since Solar System Processing takes {\tt DiaSource}s as input, so any 
Special Programs images that can be run through the Alert Pipeline can 
also be incorporated into Solar System Processing.


\subsubsection{Data Release Processing}\label{sssec:proc_reg_dr}

\textbf{Difference images, {\tt DiaSource} and {\tt DiaObject} catalogs -- }
As all visits can contribute to the time-domain astronomy science goals 
of the LSST, all Special Programs data that {\it can} be processed with 
the difference image analysis (DIA) pipeline alongside the WFD visits 
{\it should} be.
All of this processing should use the same template image for a given
field.
Users who want, e.g., only {\tt DiaSources} a given DDF, would be 
able to write queries using the region and program labels in the catalog.

\textbf{Processed visit images, {\tt Source} and {\tt ForcedSource} catalogs -- }
For the same reasons as above, all Special Programs data that 
{\it can} be processed with the Data Release pipieline alongside the WFD 
visits {\it should} be.

\textbf{Deep coadds and the {\tt Object} catalog -- }
Some of the core LSST science goals require a WFD main survey data 
products of nearly uniform depth.
Whether and how to include any Special Programs data in the deep image 
coadds and the corresponding {\tt Object} catalog is left entirely to the 
discretion of the RDM team in Operations.

For example, perhaps Special Programs images will only be included when 
they bring additional area to the same depth as the rest of the WFD, or 
when they suppress edge effects or low-order modes in the 
all-sky photometric solutions.

For stacked images and their associated catalogs, the region labels should be
included (but the program labels would not be needed or possible).


\subsection{Special Processing}\label{ssec:proc_special}

As described in Section~\ref{ssec:sci_sproc}, 
Special Processing should be done by Rubin Data Management to 
produce unique and separate data products
for Special Programs when it is both possible and necessary.

In short, \emph{possible} means that original or reconfigured versions of the LSST
Science Pipelines can be used , and \emph{necessary} means the primary science goal for Special Program
could not be met without the data products produced by the Special Processing.
The definitions of possible and necessary, and the scope of Special Processing,
are ultimately left to the discretion of Rubin Data Management in Operations.

Specific examples are provided only to illustrate this interpretation of possible and necessary.
These examples do not place limits on what Special Processing might be done.

\begin{itemize}

\item \textbf{Possible and necessary:}
in order to detect high-redshift (faint) galaxies in the DDFs,
Rubin Data Management uses the LSST Science Pipelines to deeply
coadd images for each field, and store the results of source
detection and characterization in unique and separate tables that
are included in the annual data release (Section~\ref{ssec:proc_rdm_ddf}).

\item \textbf{Possible but not necessary:}
a time-domain mini-survey that uses standard visits \emph{could}
have separate difference-image analysis object and source catalogs
generated, but this is not necessary as the science goals for the
mini-survey can be met by processing its data with regular Prompt
Processing (Section~\ref{ssec:sci_pproc}), and ensuring the
data is properly labeled (Section~\ref{ssec:sci_labels}).

\item \textbf{Possible but not necessary (secondary science goals):}
a time-domain mini-survey (or DDF) has a secondary science goal of detecting
precursor outbursts for transients, which requires coadding images
within windows of days, weeks, and months to reach various depths.
This set of custom coadds may be considered as ``not necessary" and requiring 
User-Generated Processing.

\item \textbf{Necessary but not possible:}
in order to find the most distant, faint Kuiper Belt Objects in the DDF,
a specialized, computationally intensive form of ``shift-and-stack" processing
is required for detection, but such algorithms are not used by the 
LSST Science Pipelines and so User-Generated Processing will be needed (Section~\ref{ssec:SPCS_TNO}).
A second example here is a twilight survey that uses non-standard visits 
which are outside the boundaries of what the LSST
Science Pipelines can process (Section~\ref{ssec:proc_bounds}).

\end{itemize}

\textbf{Tables should be joinable -- } where feasible.

\textbf{A note about intermediate-depth ``custom" coadds -- }
As with the annual WFD deeply coadded images and associated catalogs, RDM would 
only generate one coadd (including all images to date) for a given special region.
Custom coadds (e.g., weekly, monthly) for very specific science goals are considered 
user-generated data products, for both WFD and Special Programs.



\subsubsection{Deep Drilling Fields}

As the DDFs will likely be observed with standard or alternative standard 
visits, it is likely that RDM will be able to reconfigure existing pipelines 
to process the DDF data and produce ``unique and separate" DDF data products.

For example, RDM-generated ``unique and separate" DDF data products might 
include:
\begin{itemize}
\item nightly-coadded images (24 h)
\item nightly-coadded difference images (24 h)
\item {\tt DiaSource}- and {\tt DiaObject}-like catalogs for the nightly-coadds (24 h)
\item deeply-coadded images (all images to date; yearly)
\item templates for the nightly-coadded difference images (yearly)
\item {\tt Source}- and {\tt Object}-like catalogs for the nightly-coadded and deeply-coadded images (yearly)
\end{itemize}


\subsubsection{Short-Exposure Mini-Surveys}

As of the Phase 2 SCOC recommendations \citedsp{PSTN-055}, three kinds of 
short-exposure mini-surveys were under consideration: 
a static short exposure map of the sky in $ugrizy$ for calibration; 
a static to transient short exposure survey; and 
an Near-Earth Objects (NEO) twilight survey.

If either the transients or NEO short-exposure suvey is executed, and if 
RDM finds that the LSST Science Pipelines and, specifically, template images 
can be made and difference image analysis (DIA) run, then the RDM-generated 
data products may be similar to the Prompt data products (potentially 
including alerts; Section 3 of \citeds{lse-163}).

If either of the static short-exposure mini-surveys is executed, and if 
RDM finds that the LSST Science Pipelines can be reconfigured and used 
for short exposures, then the RDM-generated data products would likely be 
of a similar format to the Data Release data products 
(Section 4, \citeds{lse-163}).
For example, a separate repository of processed visit images and coadded 
images, and separate (but joinable) {\tt Source}, {\tt ForcedSource}, and 
{\tt Object} catalogs.


\subsubsection{Mini-Surveys}

The cases where ``unique and separate" data products for mini-surveys are 
needed to reach the science goals of a Special Program, and are possible for 
RDM to generate, are most likely to be of a similar format to the annual 
Data Release data products: static-sky coadded images and associated 
{\tt Source}- and {\tt Object}-like cataogs for standard or alternative visits.

In cases where the observations are all obtained with a short season 
(e.g., a week spent observing a specific region), such ``annual" 
data products might be generated and released on an intermediate time scale, 
if resources allow.


\subsubsection{Target-of-Opportunity (TOO) Observations}

Options for RDM to process TOO observations, especially during the first year of Operations 
when the template coverage will be low, are discussed in more detail in 
\citeds{rtn-008}.


\subsection{User-Generated Processing}\label{ssec:proc_user}

Science goals that require data products which are not possible to create with 
the original or reconfigured versions of the LSST Science Pipelines, 
and/or for which new algorithmic development or significant computational resources 
are needed, will require user processing and user-generated data products.
As described above, custom coadds (e.g., weekly, monthly) are also left to users 
to generate, as required by their specific science goals.

Users will have access to the LSST Science Pipelines and data processing 
infrastructure, as well as dedicated computational resources next-to-the-data, 
via the Rubin Science Platform; \citeds{lse-319}.
Details of the planned ``User Batch" facility for data processing are described in 
\citeds{dmtn-202}.
Very computationally intense user processing might require external resources. 

It is expected that some User-Generated pipelines and data products 
might be ``adopted" or ``federated" into the LSST Science Pipelines and the Prompt 
and Data Release data products, however, details regarding the federation of 
user-generated data products are to be provided elsewhere.

\textbf{A note prompt processing and alert production -- }
As the latency on processed visit image availability has an 80-hour
embargo, no user-generated pipeline will be able to process Special Programs 
data on a timescale similar to prompt processing and alert production 
(60 seconds to 24 hours).
No user-generated pipeline may contribute alerts to the LSST alert stream on 
any timescale.

Appendix~\ref{sec:spcs} provides more detailed, step-by-step data processing examples 
for some potential Special Programs as further illustration.

\subsubsection{Deep Drilling Fields}

User-generated data products might include, for example, DDF images coadded on custom 
timescales (e.g., weekly, monthly), or coadded using algorithms outside of the LSST 
Science Pipelines.


\subsubsection{Short-Exposure Mini-Surveys}

Short-exposure images obtained during twilight, which will have a very bright sky 
background unlike other LSST images, might require user-generated algorithms to 
subtract the high sky background. 

Short-exposure images obtained during the night would have fewer stars for 
astrometric and photometric calibration, and might require user-generated 
processing pipelines.


\subsubsection{Mini-Surveys}

Mini-surveys with time-domain science goals that aren't met by the Prompt pipelines, 
e.g., those that require difference imaging with coadded images on an intermediate 
timescale (e.g., a weekly stack), would require user-generated processing.
