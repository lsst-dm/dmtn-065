\section{Processing Data from Special Programs}\label{sec:proc}

A discussion of the anticipated details and challenges related to 
obtaining and processing data from Special Programs.

Appendix~\ref{sec:spcs} provides detailed examples for the processing
of data from Special Programs, including scenarios in which regular,
Special, and User-Generated Processing are all involved.

\subsection{Boundaries on Non-Standard Visits} \label{ssec:proc_bounds}

Special Programs that do not use standard or alternative standard visits
might be affected by hardware or processing boundaries.

\subsubsection{Hardware Boundaries}\label{ssec:proc_bounds_hardware}

Appendix~\ref{sec:hardbounds} lists all of the hardware boundaries that 
might constrain the potential diversity of Special Programs data.

In general, the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.

A few potential challenges posed by hardware
boundaries are summarized below.

\begin{itemize}

\item \textbf{Short exposures --}
Special Programs that use short exposures would be limited to the
minimum exposure time is 1 second (stretch goal: 0.1 seconds).
There is a potential hardware boundary that limits the readout rate to 1 
every 15 seconds, which would affect the image acquisition rate and 
increase the overheads on short exposures.

\item \textbf{Repeated pointing --}
Special Programs which require the \emph{exact same} field pointing and 
rotation for \emph{every exposure} (to sub-arcsecond levels) might run 
into hardware boundaries on pointing and tracking.

\item \textbf{Twilight images --}
Special Programs that obtain twilight images will be subject to safe
limits on sky background flux, as with any astronomical camera.

\end{itemize}

Finally, as a side note, Special Programs that request a high number of 
filter changes and/or long slews could be inefficient due to large overheads,
but would not be limited by hardware boundaries.

\subsubsection{Processing Boundaries}\label{ssec:proc_bounds_processing}

Appendix~\ref{sec:procbounds} describes the boundaries on what types of visits 
can be processed and calibrated by the Data Management System and the LSST
Science Pipelines.

Most of the currently-proposed Special Programs in \citeds{PSTN-055}
are not anticipated to be limited by hardware boundaries.
However, those which use non-standard visits, especially those with
short exposure time or those obtained during twilight, might
be affected by processing boundaries.

The most likely challenges posed by processing
boundaries are summarized below.

\begin{itemize}

\item \textbf{Very short exposures --}
Special Programs which use very short ($<$2 sec) exposures 
could be difficult to reduce due to an incompletely-formed PSF 
(Section~\ref{ssec:procbounds_expt}).
The Data Management System is required to be able to process exposure 
times as low as 1 second, but it is known that such short exposures might 
have degraded image quality.

\item \textbf{Very short or very long exposures --}
Special Programs that use very short or very long ($>$150 sec) 
exposures could be difficult to calibrate due to having too few 
(or too few unsaturated) stars.

\item \textbf{Twilight images --}
For Special Programs which obtain images with very bright sky backgrounds
(twilight images), it is currently unclear whether they can be processed
with the LSST Science Pipelines; User-Generated Processing might be needed.

\item \textbf{Streaked images --}
The full reduction and calibration of data from any Special Programs that 
use non-sidereal tracking, which produce images with star streaks, is
currently beyond the scope of the LSST Science Pipelines; 
User-Generated Processing would be needed.

\end{itemize}

\subsection{Regular (non-special) processing}\label{ssec:proc_reg}

Recall that the term ``regular processing" is used only within this document,
and refers to the image processing pipelines that are designed for, 
and will be applied to, the WFD program's observations (Section~\ref{sec:intro}).

Decisions about when to apply regular processing to Special Programs data,
or when to include it in the data products for the WFD program 
(e.g., if it improves the all-sky coadds), 
are ultimately left to the discretion of the Rubin Observatory's 
Data Management and System Performance teams.


\subsubsection{Prompt Processing and Alert Production}\label{sssec:proc_reg_prompt}

As described in Section~\ref{ssec:sci_pproc}, 
all visits that \emph{can} be processed by the Prompt pipelines and generate 
alerts \emph{should} be, in support of time domain and Solar System science goals.

\textbf{The meaning of ``can be processed".}
The condition ``can be processed" is ultimately left to the discretion of
Rubin Data Management in Rubin Operations, but is expected to include
all standard and alternative visits in sky regions for which a template image exists.
This might also include some non-standard visits (shorter or longer exposures), 
as long as they can be processed by the Prompt pipeline and an appropriate template image exists.
Visits with very short or very long exposure times (or very bright sky 
backgrounds) might be excluded if they would need specialized algorithms for,
e.g., instrument signature removal, difference-imaging, template-generation 
(Section~\ref{ssec:proc_bounds}).

\textbf{The use of specialized (alternative) template images.}
If a Special Program's primary science goal requires specialized templates and 
Prompt processing, the Data Management System will have the capability to load 
and use an alternative template for some sky regions, based on the image metadata 
(i.e., the labels described in Section~\ref{ssec:sci_labels}). 
However, there would not be enough memory to hold alternative templates 
for the whole sky.

\textbf{WFD and Special Program data would co-reside.}
No ``unique and separate" data products for the Special Progams would be 
produced by regular Prompt processing.
Special Programs data that is processed by the Prompt pipeline would 
contribute to the Prompt data products for the WFD program as 
described in Section 3 of the DPDD \citedsp{lse-163}. 
These data products are the results of Difference Image Analysis (DIA),
such as the difference images, catalogs of sources detected in difference
images ({\tt DiaSources}) and associated static-sky {\tt DiaSources}
into {\tt DiaObjects}, and alert packets.

Including visits from Special Programs in regular Prompt processing alongside
vists from the WFD program is not, in general, anticipated to affect WFD science goals.
For example, analyses for a WFD-only subset could still be done using the program and
region labels described in Section~\ref{ssec:sci_labels}, which would be
propogated to difference images, difference-image catalogss, and alerts.

\textbf{Potential issues with Prompt processing for untiled sequences from Special Programs.}
There are two potential issues with Prompt processing for DDFs, or any mini-survey 
that obtains a sequence of untiled images: images at the same pointing or which overlap.
For example, a DDF which obtains a hour-long series of about a hundred images at the same coordinates,
every few nights for a few months.

\begin{enumerate}

\item {\tt DiaObject} histories may become too large for the sizing model.
Alert packets contain the full records of all associated 
{\tt DiaSources} from the past 12 months, but the alert
stream bandwidth is sized for the expected histories for
WFD program fields. 
The Prompt pipeline resources are also sized for the
WFD program, and it might not be possible to load up
thousands of epochs at a time.
The Data Management team will have to test the realized
capabilities of Prompt processing and alert distribtuion,
and potentially impose a mitigation strategy such as
limiting histories to the last $N$ observations instead
of the last 12 months in heavily-observed regions.

\item The association of {\it new} {\tt DiaSources} into {\tt DiaObjects} 
may be compromised.
For consecutive images, processing for the second image begins when the processing for the 
first image is only halfway done.
At this point, the {\tt DiaObject} catalog has 
not yet been updated with the new {\tt DiaSources} detected in the first image.
Thus, the {\tt DiaSource}s from images one and two for a new transient 
would not be associated with a single {\tt DiaObject}, but instead would 
each instantiate a new {\tt DiaObject}.

\end{enumerate}

These two potential issues pose challenges, but are not showstoppers in processing 
Special Programs data with the Prompt pipelines. 
The overall impact on time-domain science would still be positive, even 
if mitigations are needed for these issues.
For example, brokers and users would be able to use the region and program labels
in the data as context (i.e., as flags) and avoid including 
limited-history or potentially-compromised {\tt DiaSources} in their
analyses if necessary.

\subsubsection{Solar System Processing}\label{sssec:proc_reg_ss}

Since Solar System Processing takes {\tt DiaSource}s as input, any 
Special Programs images that are processed by the Prompt pipeline
could be incorporated into Solar System Processing as well.

\subsubsection{Data Release Processing}\label{sssec:proc_reg_dr}

\textbf{Difference images, {\tt DiaSource} and {\tt DiaObject} catalogs -- }
As all visits can contribute to the time-domain astronomy science goals 
of the LSST, all Special Programs data that {\it can} be processed with 
the difference image analysis (DIA) pipeline alongside the WFD visits 
{\it should} be.
All of this processing should use the same template image for a given
field.
Users who want, e.g., only {\tt DiaSources} a given DDF, would be 
able to write queries using the region and program labels in the catalog.

\textbf{Processed visit images, {\tt Source} and {\tt ForcedSource} catalogs -- }
For the same reasons as above, all Special Programs data that 
{\it can} be processed with the Data Release pipieline alongside the WFD 
visits {\it should} be.

\textbf{Deep coadds and the {\tt Object} catalog -- }
Some of the core LSST science goals require a WFD main survey data 
products of nearly uniform depth.
Whether and how to include any Special Programs data in the deep image 
coadds and the corresponding {\tt Object} catalog is left entirely to the 
discretion of the RDM team in Operations.

For example, perhaps Special Programs images will only be included when 
they bring additional area to the same depth as the rest of the WFD, or 
when they suppress edge effects or low-order modes in the 
all-sky photometric solutions.

For stacked images and their associated catalogs, the region labels should be
included (but the program labels would not be needed or possible).


\subsection{Special Processing}\label{ssec:proc_special}

As described in Section~\ref{ssec:sci_sproc}, 
Special Processing should be done by Rubin Data Management to 
produce unique and separate data products
for Special Programs when it is both possible and necessary.

In short, \emph{possible} means that original or reconfigured versions of the LSST
Science Pipelines can be used , and \emph{necessary} means the primary science goal for Special Program
could not be met without the data products produced by the Special Processing.
The definitions of possible and necessary, and the scope of Special Processing,
are ultimately left to the discretion of Rubin Data Management in Operations.

Specific examples are provided only to illustrate this interpretation of possible and necessary.
These examples do not place limits on what Special Processing might be done.

\begin{itemize}

\item \textbf{Possible and necessary:}
in order to detect high-redshift (faint) galaxies in the DDFs,
Rubin Data Management uses the LSST Science Pipelines to deeply
coadd images for each field, and store the results of source
detection and characterization in unique and separate tables that
are included in the annual data release (Section~\ref{ssec:proc_rdm_ddf}).

\item \textbf{Possible but not necessary:}
a time-domain mini-survey that uses standard visits \emph{could}
have separate difference-image analysis object and source catalogs
generated, but this is not necessary as the science goals for the
mini-survey can be met by processing its data with regular Prompt
Processing (Section~\ref{ssec:sci_pproc}), and ensuring the
data is properly labeled (Section~\ref{ssec:sci_labels}).

\item \textbf{Possible but not necessary (secondary science goals):}
a time-domain mini-survey (or DDF) has a secondary science goal of detecting
precursor outbursts for transients, which requires coadding images
within windows of days, weeks, and months to reach various depths.
This set of custom coadds may be considered as ``not necessary" and requiring 
User-Generated Processing.

\item \textbf{Necessary but not possible:}
in order to find the most distant, faint Kuiper Belt Objects in the DDF,
a specialized, computationally intensive form of ``shift-and-stack" processing
is required for detection, but such algorithms are not used by the 
LSST Science Pipelines and so User-Generated Processing will be needed (Section~\ref{ssec:SPCS_TNO}).
A second example here is a twilight survey that uses non-standard visits 
which are outside the boundaries of what the LSST
Science Pipelines can process (Section~\ref{ssec:proc_bounds}).

\end{itemize}

\textbf{Tables should be joinable -- } where feasible.

\textbf{A note about intermediate-depth ``custom" coadds -- }
As with the annual WFD deeply coadded images and associated catalogs, RDM would 
only generate one coadd (including all images to date) for a given special region.
Custom coadds (e.g., weekly, monthly) for very specific science goals are considered 
user-generated data products, for both WFD and Special Programs.



\subsubsection{Deep Drilling Fields}

As the DDFs will likely be observed with standard or alternative standard 
visits, it is likely that RDM will be able to reconfigure existing pipelines 
to process the DDF data and produce ``unique and separate" DDF data products.

For example, RDM-generated ``unique and separate" DDF data products might 
include:
\begin{itemize}
\item nightly-coadded images (24 h)
\item nightly-coadded difference images (24 h)
\item {\tt DiaSource}- and {\tt DiaObject}-like catalogs for the nightly-coadds (24 h)
\item deeply-coadded images (all images to date; yearly)
\item templates for the nightly-coadded difference images (yearly)
\item {\tt Source}- and {\tt Object}-like catalogs for the nightly-coadded and deeply-coadded images (yearly)
\end{itemize}


\subsubsection{Short-Exposure Mini-Surveys}

As of the Phase 2 SCOC recommendations \citedsp{PSTN-055}, three kinds of 
short-exposure mini-surveys were under consideration: 
a static short exposure map of the sky in $ugrizy$ for calibration; 
a static to transient short exposure survey; and 
an Near-Earth Objects (NEO) twilight survey.

If either the transients or NEO short-exposure suvey is executed, and if 
RDM finds that the LSST Science Pipelines and, specifically, template images 
can be made and difference image analysis (DIA) run, then the RDM-generated 
data products may be similar to the Prompt data products (potentially 
including alerts; Section 3 of \citeds{lse-163}).

If either of the static short-exposure mini-surveys is executed, and if 
RDM finds that the LSST Science Pipelines can be reconfigured and used 
for short exposures, then the RDM-generated data products would likely be 
of a similar format to the Data Release data products 
(Section 4, \citeds{lse-163}).
For example, a separate repository of processed visit images and coadded 
images, and separate (but joinable) {\tt Source}, {\tt ForcedSource}, and 
{\tt Object} catalogs.


\subsubsection{Mini-Surveys}

The cases where ``unique and separate" data products for mini-surveys are 
needed to reach the science goals of a Special Program, and are possible for 
RDM to generate, are most likely to be of a similar format to the annual 
Data Release data products: static-sky coadded images and associated 
{\tt Source}- and {\tt Object}-like cataogs for standard or alternative visits.

In cases where the observations are all obtained with a short season 
(e.g., a week spent observing a specific region), such ``annual" 
data products might be generated and released on an intermediate time scale, 
if resources allow.


\subsubsection{Target-of-Opportunity (TOO) Observations}

Options for RDM to process TOO observations, especially during the first year of Operations 
when the template coverage will be low, are discussed in more detail in 
\citeds{rtn-008}.


\subsection{User-Generated Processing}\label{ssec:proc_user}

Science goals that require data products which are not possible to create with 
the original or reconfigured versions of the LSST Science Pipelines, 
and/or for which new algorithmic development or significant computational resources 
are needed, will require user processing and user-generated data products.
As described above, custom coadds (e.g., weekly, monthly) are also left to users 
to generate, as required by their specific science goals.

Users will have access to the LSST Science Pipelines and data processing 
infrastructure, as well as dedicated computational resources next-to-the-data, 
via the Rubin Science Platform; \citeds{lse-319}.
Details of the planned ``User Batch" facility for data processing are described in 
\citeds{dmtn-202}.
Very computationally intense user processing might require external resources. 

It is expected that some User-Generated pipelines and data products 
might be ``adopted" or ``federated" into the LSST Science Pipelines and the Prompt 
and Data Release data products, however, details regarding the federation of 
user-generated data products are to be provided elsewhere.

\textbf{A note prompt processing and alert production -- }
As the latency on processed visit image availability has an 80-hour
embargo, no user-generated pipeline will be able to process Special Programs 
data on a timescale similar to prompt processing and alert production 
(60 seconds to 24 hours).
No user-generated pipeline may contribute alerts to the LSST alert stream on 
any timescale.

Appendix~\ref{sec:spcs} provides more detailed, step-by-step data processing examples 
for some potential Special Programs as further illustration.

\subsubsection{Deep Drilling Fields}

User-generated data products might include, for example, DDF images coadded on custom 
timescales (e.g., weekly, monthly), or coadded using algorithms outside of the LSST 
Science Pipelines.


\subsubsection{Short-Exposure Mini-Surveys}

Short-exposure images obtained during twilight, which will have a very bright sky 
background unlike other LSST images, might require user-generated algorithms to 
subtract the high sky background. 

Short-exposure images obtained during the night would have fewer stars for 
astrometric and photometric calibration, and might require user-generated 
processing pipelines.


\subsubsection{Mini-Surveys}

Mini-surveys with time-domain science goals that aren't met by the Prompt pipelines, 
e.g., those that require difference imaging with coadded images on an intermediate 
timescale (e.g., a weekly stack), would require user-generated processing.
